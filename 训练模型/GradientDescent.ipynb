{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "线性回归模型的MSE成本函数为凸函数，避免了局部最小值；无论走法如何，都可以趋近到全局最小值\n",
    "\n",
    "使用梯度下降时，需要保证所有特征值的大小比例都差不多，否则收敛时间会长很多"
   ],
   "id": "76c152e959898ef4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "批量梯度下降：\n",
    "\n",
    "成本函数的偏导数：$\\frac{\\partial}{\\partial \\theta_{j}}MSE(\\theta) = \\frac{2}{m}\\sum^{m}_{i=1}(\\theta^{T}x^{(i)} - y^(i))x^{(i)}_{j}$\n",
    "\n",
    "成本函数的梯度向量：\n",
    "$$\n",
    "\\mathbf{\\nabla_{\\theta}MSE(\\theta)} = \\begin{pmatrix}\n",
    "\\frac{\\partial}{\\partial \\theta_{0}}MSE(\\theta) \\\\\n",
    "\\frac{\\partial}{\\partial \\theta_{1}}MSE(\\theta) \\\\\n",
    "...\\\\\n",
    "\\frac{\\partial}{\\partial \\theta_{n}}MSE(\\theta)\n",
    "\\end{pmatrix} =  \\frac{2}{m}X^{T}(X\\theta-y)\n",
    "$$\n",
    "\n",
    "梯度下降步骤：$\\theta^{(下一步)} = \\theta - \\eta\\nabla_{\\theta}MSE(\\theta)$  $\\eta$为学习率\n"
   ],
   "id": "fe5a6bb82cd77507"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T12:25:14.109279Z",
     "start_time": "2025-11-08T12:25:13.612148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "X=2*np.random.rand(100, 1)\n",
    "y=4+3*X+np.random.randn(100, 1)\n",
    "X_b=np.c_[np.ones((100,1)), X]\n",
    "eta = 0.1\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "theta = np.random.randn(2,1)\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta)-y)\n",
    "    theta -= eta * gradients\n",
    "theta"
   ],
   "id": "c77bd630cd8fcae6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.822484  ],\n",
       "       [3.31786586]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "随机梯度下降：每一步在训练集中随机选择一个实例，并且仅基于该单个实例来计算梯度。它可以帮助算法跳出局部最小值，但永远定位不出最小值，可以使用逐步降低学习率的方法。（确定每个迭代学习率的函数叫做学习率调度）\n",
    "\n",
    "使用随机梯度下降时，训练实例必须满足IID， 在训练过程中需要对实例进行随即混洗"
   ],
   "id": "69125b2c762282dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:06:36.466606Z",
     "start_time": "2025-11-08T13:06:36.420085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_epochs=50\n",
    "t0, t1=5, 50\n",
    "def learning_schedule(t):\n",
    "    return t0/(t+t1)\n",
    "theta = np.random.randn(2,1)\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(n_epochs):\n",
    "        random_index = np.random.randint(m)\n",
    "        xi = X_b[random_index:random_index+1]\n",
    "        yi = y[random_index:random_index+1]\n",
    "        gradients = 2*xi.T.dot(xi.dot(theta)-yi)\n",
    "        eta=learning_schedule(epoch*m+i)\n",
    "        theta = theta-eta*gradients\n",
    "theta"
   ],
   "id": "1b5cfa6863692091",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.80396035],\n",
       "       [3.38254235]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-08T13:10:25.502144Z",
     "start_time": "2025-11-08T13:10:24.304679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter=1000, tol=1e3, penalty=None, eta0=0.1)\n",
    "sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.intercept_, sgd_reg.coef_"
   ],
   "id": "6c2e78442e23d574",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.7626581]), array([3.35465825]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "小批量梯度下降：在每一步中，在称为小型批量的随机实例集上计算梯度。可通过矩阵操作的硬件优化来提高性能\n",
    "\n",
    "它比随机梯度下降走得更接近最小值，但可能很难拜托局部最小值"
   ],
   "id": "859f0981f3b8107a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
