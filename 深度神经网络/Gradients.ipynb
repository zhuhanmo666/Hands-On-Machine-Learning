{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Glorot初始化（使用逻辑激活函数）：\n",
    "\n",
    "正态分布，其均值为0，方差为$\\sigma^2=\\frac{1}{fan_{avg}}$,或$-r$和$+r$之间的均匀分布，其中$r=\\sqrt{\\frac{3}{fan_{avg}}}$\n",
    "\n",
    "其中$fan_{avg}=\\frac{(fan_{in}+fan_{out})}{2}$\n",
    "\n",
    "```python\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "```\n",
    "\n",
    "Variance Scaling初始化：\n",
    "\n",
    "```python\n",
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                                 distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"sigmoid\", kernel_initializer=he_avg_init)\n",
    "```\n",
    "\n",
    "ELU激活函数：$$\n",
    "\\mathrm{ELU}_\\alpha(z) =\n",
    "\\begin{cases}\n",
    "\\alpha \\left( \\exp(z) - 1 \\right) & \\text{如果 } z < 0 \\\\\n",
    "z & \\text{如果 } z \\geq 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "它的计算较慢但是收敛速度更快。\n",
    "\n",
    "SELU激活函数： $\\mathrm{SELU}(z)=\\lambda \\cdot \\mathrm{ELU}(z)$\n",
    "\n",
    "自归一化的条件：\n",
    "1. 输入特征必须是标准化的（mean=0，std=1）\n",
    "2. 每个隐藏层的权重使用LeCun正态初始化，即`kernel_initializer=\"lecun_normal\"`\n",
    "3. 网络架构必须是顺序的\n",
    "4. 所有层都是密集层\n",
    "\n",
    "通常SELU>ELU>leaky ReLU（及其变体）>ReLU>tanh>logistic\n",
    "\n",
    "如果网络的架构不能自归一化，那么ELU的性能\n",
    "可能会优于SELU（因为SELU在z=0时不平滑）。如果你非常关心运行时\n",
    "延迟，那么你可能更喜欢leaky ReLU。如果你不想调整其他超参数，则\n",
    "可以使用Keras使用的默认α值（例如，leaky ReLU为0.3）。如果你有\n",
    "空闲时间和计算能力，则可以使用交叉验证来评估其他激活函数，例\n",
    "如，如果网络过拟合，则为RReLU；如果你的训练集很大，则为PReLU。如果你将速度放在首位，那么\n",
    "ReLU可能仍然是最佳选择。\n",
    "也就是说，ReLU是迄今为止最常用的激活函数\n",
    "\n",
    "\n",
    "leakyReLU:\n",
    "```python\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    [...]\n",
    "])\n",
    "```\n",
    "\n",
    "SELU:\n",
    "```python\n",
    "layer = keras.layers.Dense(10, activation=\"selu\", kernel_initializer=\"lecun_normal\")\n",
    "```"
   ],
   "id": "5bddc95a0356b0cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "批量归一化算法：\n",
    "1. $\\mu_{\\mathrm{B}} = \\frac{1}{m_{\\mathrm{B}}} \\sum_{i=1}^{m_{\\mathrm{B}}} x^{(i)}$\n",
    "\n",
    "2. $\\sigma_{\\mathrm{B}}^2 = \\frac{1}{m_{\\mathrm{B}}} \\sum_{i=1}^{m_{\\mathrm{B}}} \\left(x^{(i)} - \\mu_{\\mathrm{B}}\\right)^2$\n",
    "\n",
    "3. $\\hat{x}^{(i)} = \\frac{x^{(i)} - \\mu_{\\mathrm{B}}}{\\sqrt{\\sigma_{\\mathrm{B}}^2 + \\varepsilon}}$\n",
    "\n",
    "4. $z^{(i)} = \\gamma \\otimes \\hat{x}^{(i)} + \\beta$\n",
    "\n",
    "其中，$\\mu_B$是输入均值的向量，在整个小批量B上评估;$\\sigma_B$是输入标准差的向量，也在整个小批量中进行评估;$m_B$是小批量中的实例数量;$X_{(i)}$是实例$i$的零中心和归一化输入的向量;$\\gamma$是该层的输出缩放参数向量;$\\otimes$表示逐元素乘法;$\\beta$是层的输出移动（偏移）参数向量，每个输入都通过其相应的移动参数进行偏移;$\\epsilon$为平滑项;$z^{(i)}$是BN操作的输出，是输入的缩放和偏移版本。\n",
    "\n",
    "在每个批归一化层中学习了四个参数向量：通过常规反向传播学习$\\gamma$（输出缩放向量）和$\\beta$（输出偏移向量），和使用指数移动平均值估\n",
    "计的$\\mu$（最终的输入均值向量）和$\\sigma$（最终输入标准差向量）"
   ],
   "id": "a7c3fe56a0c5be79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T15:15:59.168049Z",
     "start_time": "2026-02-06T15:15:59.081448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#用keras实现批量归一化\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ],
   "id": "a31cfe41e3bc891d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 784)               3136      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 300)               1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 100)               400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271346 (1.04 MB)\n",
      "Trainable params: 268978 (1.03 MB)\n",
      "Non-trainable params: 2368 (9.25 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T15:16:29.802436Z",
     "start_time": "2026-02-06T15:16:29.797439Z"
    }
   },
   "cell_type": "code",
   "source": "[(var.name, var.trainable) for var in model.layers[1].variables]",
   "id": "8b165437c1c057f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization_3/gamma:0', True),\n",
       " ('batch_normalization_3/beta:0', True),\n",
       " ('batch_normalization_3/moving_mean:0', False),\n",
       " ('batch_normalization_3/moving_variance:0', False)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T15:17:20.443941Z",
     "start_time": "2026-02-06T15:17:20.378074Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\", use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"elu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ],
   "id": "6cb0aed3ed5db96b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Update $\\hat{v}$:\n",
    "\n",
    "$\\hat{v}\\leftarrow \\hat{v}\\times momentum + v\\times(1-momentum)$"
   ],
   "id": "179793ea7761f814"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T15:19:38.311357Z",
     "start_time": "2026-02-06T15:19:38.296151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#梯度裁剪\n",
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ],
   "id": "78ebee3e41c64805",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
