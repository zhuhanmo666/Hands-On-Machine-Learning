{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#l2正则化\n",
    "from tensorflow import keras\n",
    "layer = keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "#l2（）函数返回一个正则化函数，在训练过程中的每个步骤都将调用该正则化函数来计算正则化损失。然后将其添加到最终损失中。如果需要l1正则化，可以只使用keras.regularizers.l1（）。如果你同时需要l1和l2正则化，请使用keras.regularizers.l1_l2（）\n",
    "\n",
    "#为带有一些默认参数值的任何可调用对象创建一个小的包装函数\n",
    "from functools import partial\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\",\n",
    "                     kernel_initializer=\"glorot_uniform\")\n",
    "])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#dropout\n",
    "#经过dropout训练的神经元不能与其相邻的神经元相互适应，它们必须自己发挥最大的作用。它们也不能过分依赖少数输入神经元，它们必须注意每个输入神经元。它们最终对输入的微小变化不太敏感。最后，你将获得一个更有鲁棒性的网络，该网络有更好的泛化能力。\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "#如果你发现模型过拟合，则可以提高dropout率。相反，如果模型欠拟合训练集，则应尝试降低dropout率。\n",
    "#dropout确实会明显减慢收敛速度，但是如果正确微调，通常会导致更好的模型。"
   ],
   "id": "30eb2606fef0505d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#蒙特卡罗Dropout\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,  # 总样本数\n",
    "    n_features=20,   # 特征数\n",
    "    n_classes=2,     # 二分类\n",
    "    n_redundant=0,   # 无冗余特征\n",
    "    n_informative=20, # 所有特征都有信息量\n",
    "    random_state=42\n",
    ")\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp # 0.5 * 0.8 = 0.4 of total\n",
    ")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "np.round(model.predict(X_test_scaled[:1]), 2) ,np.round(y_probas[:, :1], 2) ,np.round(y_proba[:1], 2)\n",
    "#accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "\n",
    "#如果你的模型包含在训练过程中以特殊方式运行的其他层（例如BatchNormalization层），则应该使用以下MCDropout类[5]来替换Dropout层\n",
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ],
   "id": "86f741401c9a6b4c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#最大范数正则化:不会把正则化损失项添加到总体损失函数中。取而代之的是，通常在每个训练步骤后通过计算||w||2来实现，如有需要，需要缩放w。\n",
    "#减小r会增加正则化的数量，并有助于减少过拟合。最大范数正则化还可以帮助缓解不稳定的梯度问题\n",
    "\n",
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_constraint=keras.constraints.max_norm(1.))"
   ],
   "id": "2c2964e363d7c632"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
